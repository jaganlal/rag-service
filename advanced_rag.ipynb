{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### https://medium.com/the-ai-forum/implementing-contextual-retrieval-in-rag-pipeline-8f1bc7cbd5e0\n",
    "\n",
    "###### RouteLLM\n",
    "###### https://www.youtube.com/watch?v=dmMzMtqM_P0\n",
    "###### https://mer.vin/2024/07/routellm-code-example/\n",
    "###### python -m routellm.calibrate_threshold --routers mf --strong-model-pct 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import getpass\n",
    "from typing import List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from langchain.retrievers import ContextualCompressionRetriever,BM25Retriever,EnsembleRetriever\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers.embeddings_redundant_filter import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import time\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from whoosh.index import create_in, open_dir, exists_in\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.qparser import QueryParser\n",
    "from pydantic import Field\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from rich import print\n",
    "\n",
    "from routellm.controller import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhooshIndexManager:\n",
    "    def __init__(self, index_dir: str = \"./storage/bm25_index\"):\n",
    "        \"\"\"\n",
    "        Initialize the Whoosh index manager.\n",
    "\n",
    "        Args:\n",
    "            index_dir (str): Directory to store the Whoosh index.\n",
    "        \"\"\"\n",
    "        self.index_dir = index_dir\n",
    "        self.schema = Schema(\n",
    "            doc_id=ID(stored=True, unique=True),\n",
    "            content=TEXT(stored=True)\n",
    "        )\n",
    "        self.index = self._initialize_index()\n",
    "\n",
    "    def _initialize_index(self):\n",
    "        \"\"\"Initialize or load the index.\"\"\"\n",
    "        if not os.path.exists(self.index_dir):\n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(self.index_dir, exist_ok=True)\n",
    "            print(f\"Created directory: {self.index_dir}\")\n",
    "            # Create a new index\n",
    "            return create_in(self.index_dir, self.schema)\n",
    "        elif exists_in(self.index_dir):\n",
    "            # Open the existing index\n",
    "            print(f\"Loading existing index from: {self.index_dir}\")\n",
    "            return open_dir(self.index_dir)\n",
    "        else:\n",
    "            # Directory exists, but it's not a valid Whoosh index\n",
    "            raise ValueError(\n",
    "                f\"The directory '{self.index_dir}' exists but does not contain a valid Whoosh index. \"\n",
    "                \"Delete the directory or ensure it contains a valid index.\"\n",
    "            )\n",
    "\n",
    "    def add_documents(self, documents: List[Document]):\n",
    "        \"\"\"Add documents to the index.\"\"\"\n",
    "        writer = self.index.writer()\n",
    "        for i, doc in enumerate(documents):\n",
    "            writer.add_document(doc_id=str(i), content=doc.page_content)\n",
    "        writer.commit()\n",
    "        print(f\"Added {len(documents)} documents to the index.\")\n",
    "\n",
    "    def search(self, query: str, top_n: int = 10) -> List[dict]:\n",
    "        \"\"\"Search the index.\"\"\"\n",
    "        with self.index.searcher() as searcher:\n",
    "            parser = QueryParser(\"content\", schema=self.schema)\n",
    "            parsed_query = parser.parse(query)\n",
    "            results = searcher.search(parsed_query, limit=top_n)\n",
    "            return [\n",
    "                {\"content\": result[\"content\"], \"doc_id\": result[\"doc_id\"]}\n",
    "                for result in results\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhooshRetriever(BaseRetriever):\n",
    "    index_manager: object = Field(...)\n",
    "    k: int = Field(default=10)\n",
    "\n",
    "    def __init__(self, index_manager, k: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize the Whoosh retriever.\n",
    "\n",
    "        Args:\n",
    "            index_manager (WhooshIndexManager): The Whoosh index manager.\n",
    "            k (int): Number of documents to retrieve.\n",
    "        \"\"\"\n",
    "        super().__init__(index_manager=index_manager,\n",
    "                         k=k)  # Initialize the BaseRetriever with Pydantic fields\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"Retrieve documents in LangChain-compatible format.\"\"\"\n",
    "        results = self.index_manager.search(query, top_n=self.k)\n",
    "        return [\n",
    "            Document(page_content=result[\"content\"], metadata={\n",
    "                     \"doc_id\": result[\"doc_id\"]})\n",
    "            for result in results\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Class - FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFAISSStorage:\n",
    "    def __init__(self, storage_path: str, embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            storage_path (str): Path to the directory where the FAISS index will be saved/loaded.\n",
    "            embeddings: Embeddings model (e.g., OpenAIEmbeddings, SentenceTransformerEmbeddings).\n",
    "        \"\"\"\n",
    "        self.storage_path = storage_path\n",
    "        self.embeddings = embeddings\n",
    "        self.vectorstore = None\n",
    "\n",
    "    def _index_exists(self) -> bool:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            bool: True if the index exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return os.path.exists(os.path.join(self.storage_path, \"index.faiss\"))\n",
    "\n",
    "    def _load_or_create_index(self):\n",
    "        if self._index_exists():\n",
    "            print(\"Loading existing FAISS index...\")\n",
    "            self.vectorstore = FAISS.load_local(self.storage_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "        else:\n",
    "            print(\"Creating new FAISS index...\")\n",
    "            self.vectorstore = FAISS.from_texts([\"\"], self.embeddings, metadatas=[{}])\n",
    "            self.save_index()\n",
    "\n",
    "    def load_index(self):\n",
    "        \"\"\"\n",
    "        Raises:\n",
    "            ValueError: If the index does not exist.\n",
    "        \"\"\"\n",
    "        if not self._index_exists():\n",
    "            raise ValueError(\"FAISS index does not exist at the specified storage path.\")\n",
    "\n",
    "        print(\"Loading existing FAISS index...\")\n",
    "        self.vectorstore = FAISS.load_local(self.storage_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    def get_index(self):\n",
    "      self.load_index()\n",
    "      return self.vectorstore\n",
    "\n",
    "    def add_documents(self, documents: list[Document]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            documents (list[Document]): List of Document objects to add to the index.\n",
    "        \"\"\"\n",
    "        if self.vectorstore is None:\n",
    "            self._load_or_create_index()\n",
    "\n",
    "        print(f\"Adding {len(documents)} documents to the FAISS index...\")\n",
    "        self.vectorstore.add_documents(documents)\n",
    "        return self.vectorstore\n",
    "\n",
    "    def save_index(self):\n",
    "        if self.vectorstore is None:\n",
    "            raise ValueError(\n",
    "                \"FAISS index not initialized. Add documents first.\")\n",
    "\n",
    "        print(\"Saving FAISS index...\")\n",
    "        self.vectorstore.save_local(self.storage_path)\n",
    "\n",
    "    def query(self, query: str, k: int = 5) -> list[Document]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (str): The query string.\n",
    "            k (int): Number of documents to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            list[Document]: List of Document objects most similar to the query.\n",
    "        \"\"\"\n",
    "        if self.vectorstore is None:\n",
    "            raise ValueError(\n",
    "                \"FAISS index not initialized. Add documents first.\")\n",
    "\n",
    "        print(f\"Querying FAISS index for: '{query}'\")\n",
    "        return self.vectorstore.similarity_search(query, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRAGPipeline:\n",
    "    def __init__(self, tpm_limit = 7000, create_contextual_rag=False, vectorstore_path=\"./storage/faiss_local\", bm25_index_dir=\"./storage/bm25_index\"):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=100,\n",
    "        )\n",
    "        #self.embeddings = OpenAIEmbeddings()\n",
    "        self.tpm_limit = tpm_limit\n",
    "        self.vectorstore_path = vectorstore_path\n",
    "        self.bm25_index_dir = bm25_index_dir\n",
    "        self.create_contextual_rag = create_contextual_rag\n",
    "        model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "        model_kwargs = {'device': 'cpu'}\n",
    "        encode_kwargs = {'normalize_embeddings': False}\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs\n",
    "        )\n",
    "        # self.llm = ChatOpenAI(\n",
    "        #     model=\"gpt-4o\",\n",
    "        #     temperature=0,\n",
    "        #     max_tokens=None,\n",
    "        #     timeout=None,\n",
    "        #     max_retries=2,\n",
    "        # )\n",
    "\n",
    "        # self.llm = ChatGroq(\n",
    "        #     model=\"llama-3.2-3b-preview\",\n",
    "        #     temperature=0,\n",
    "        #     max_tokens=None,\n",
    "        #     timeout=None,\n",
    "        #     max_retries=2,\n",
    "        # )\n",
    "\n",
    "        self.llm = ChatGroq(\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "        )\n",
    "        self.storage_class: MyFAISSStorage = MyFAISSStorage(self.vectorstore_path, self.embeddings)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-3B-Instruct\")\n",
    "        self.bm25_index_manager: WhooshIndexManager = WhooshIndexManager(self.bm25_index_dir)\n",
    "\n",
    "        self.client = Controller(\n",
    "            routers=[\"mf\"],\n",
    "            strong_model=\"groq/mixtral-8x7b-32768\",\n",
    "            weak_model=\"groq/llama-3.2-3b-preview\",\n",
    "        )\n",
    "\n",
    "    def _is_within_token_limit(self, tokenizer, document, current_tokens, tpm_limit):\n",
    "        tokens = len(tokenizer.encode(str(document)))\n",
    "        current_tokens += tokens\n",
    "\n",
    "        if current_tokens >= tpm_limit:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _generate_contextualized_chunks(self, document: str, chunks: List[Document], max_retries: int = 1, delay: int = 60) -> List[Document]:\n",
    "        contextualized_chunks = []\n",
    "        for chunk in chunks:\n",
    "            retries = 0\n",
    "            while retries <= max_retries:\n",
    "                try:\n",
    "                    context = self._generate_context(\n",
    "                        document, chunk.page_content)\n",
    "                    contextualized_content = f\"{context}\\n\\n{chunk.page_content}\"\n",
    "                    contextualized_chunks.append(\n",
    "                        Document(page_content=contextualized_content, metadata=chunk.metadata))\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if \"rate limit\" in str(e).lower() or \"exceeded\" in str(e).lower() or \"quota\" in str(e).lower():\n",
    "                        retries += 1\n",
    "                        if retries > max_retries:\n",
    "                            print(\n",
    "                                f\"Max retries ({max_retries}) exceeded for chunk: {chunk.page_content[:50]}...\")\n",
    "                            raise e\n",
    "                        delay_with_randomness = delay + random.random()\n",
    "                        print(\n",
    "                            f\"Rate limit error: {e}. Retrying chunk in {delay_with_randomness:.2f} seconds...\")\n",
    "                        time.sleep(delay_with_randomness)\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"Error processing chunk: {chunk.page_content[:50]}... Error: {e}\")\n",
    "                        raise e\n",
    "        return contextualized_chunks\n",
    "\n",
    "    def _generate_context(self, document: str, chunk: str) -> str:\n",
    "        relevant_document = self._extract_relevant_part(document, chunk)\n",
    "\n",
    "        print(f\"Length of the relevant document: {len(relevant_document)}\")\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an AI assistant specializing in document analysis. Your task is to provide brief, relevant context for a chunk of text from the whitepaper report.\n",
    "        Here is the whitepaper:\n",
    "        <document>\n",
    "        {document}\n",
    "        </document>\n",
    "\n",
    "        Here is the chunk we want to situate within the whole document::\n",
    "        <chunk>\n",
    "        {chunk}\n",
    "        </chunk>\n",
    "\n",
    "        Provide a concise context (2-3 sentences) for this chunk, considering the following guidelines:\n",
    "        Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else.\n",
    "\n",
    "        Context:\n",
    "        \"\"\")\n",
    "        messages = prompt.format_messages(\n",
    "            document=relevant_document, chunk=chunk)\n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "    def _extract_relevant_part(self, document: List[Document], chunk: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract a relevant part of the document for context generation.\n",
    "        This reduces the number of tokens sent to the LLM.\n",
    "        \"\"\"\n",
    "        # Find the position of the chunk in the document\n",
    "        chunk_start = document[0].page_content.find(chunk)\n",
    "        chunk_end = chunk_start + len(chunk)\n",
    "\n",
    "        # Extract a window of text around the chunk (e.g., 2048 characters before and after)\n",
    "        window_size = 2048\n",
    "        start = max(0, chunk_start - window_size)\n",
    "        end = min(len(document[0].page_content), chunk_end + window_size)\n",
    "\n",
    "        return document[0].page_content[start:end]\n",
    "\n",
    "    def _extract_relevant_part_with_maxtokens(self, document: List[Document], chunk: str, max_tokens: int = 2048) -> str:\n",
    "        chunk_tokens = len(self.tokenizer.encode(chunk))\n",
    "\n",
    "        # Calculate the maximum allowed tokens for context\n",
    "        max_context_tokens = max_tokens - chunk_tokens\n",
    "\n",
    "        # Estimate the number of characters per token (average is ~4 characters per token)\n",
    "        chars_per_token = 4\n",
    "        max_context_chars = max_context_tokens * chars_per_token\n",
    "\n",
    "        # Find the position of the chunk in the document\n",
    "        chunk_start = document[0].page_content.find(chunk)\n",
    "        chunk_end = chunk_start + len(chunk)\n",
    "\n",
    "        # Extract a window of text around the chunk\n",
    "        window_size = min(max_context_chars, len(document[0].page_content))\n",
    "        start = max(0, chunk_start - window_size // 2)\n",
    "        end = min(len(document[0].page_content), chunk_end + window_size // 2)\n",
    "\n",
    "        return document[0].page_content[start:end]\n",
    "\n",
    "    def get_document_chunks(self, document, max_retries=1, delay=60):\n",
    "        details = {}\n",
    "        source_document = document[0].metadata[\"source\"]\n",
    "        details[\"source\"] = source_document\n",
    "        details[\"original_chunks\"], details[\"contextualized_chunks\"] = self.split_document(document, max_retries, delay)\n",
    "        return details\n",
    "\n",
    "    def process_document(self, document, retry_document_processing, current_tokens, delay=60):\n",
    "        try:\n",
    "          source_document = document[0].metadata[\"source\"]\n",
    "          print(f\"Processing document: {source_document} with currrent tokens: {current_tokens}\")\n",
    "          details = self.get_document_chunks(document, 1, delay)\n",
    "\n",
    "          if bool(details):\n",
    "              self.create_vectorstores(details[\"original_chunks\"])\n",
    "              self.bm25_index_manager.add_documents(details[\"original_chunks\"])\n",
    "              if self.create_contextual_rag:\n",
    "                  self.create_vectorstores(details[\"contextualized_chunks\"])\n",
    "                  self.bm25_index_manager.add_documents(details[\"contextualized_chunks\"])\n",
    "\n",
    "          if self.create_contextual_rag and not self._is_within_token_limit(self.tokenizer, details, current_tokens, self.tpm_limit):\n",
    "              print(f\"TPM limit reached, current tokens are: {current_tokens}. Waiting for {delay} seconds...\")\n",
    "              time.sleep(delay)\n",
    "\n",
    "          return current_tokens\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process document: {source_document}. Error: {e}\")\n",
    "            if delay > 60: # Hack: it's retrying, don't append again\n",
    "              retry_document_processing.append(document)\n",
    "\n",
    "            return current_tokens\n",
    "    def process_document_decommision(self, document: str) -> Tuple[List[Document], List[Document]]:\n",
    "        chunks = self.text_splitter.create_documents([document])\n",
    "        contextualized_chunks = self._generate_contextualized_chunks(document, chunks)\n",
    "        return chunks, contextualized_chunks\n",
    "\n",
    "    def split_document(self, document: str, max_retries: int = 1, delay: int = 60) -> Tuple[List[Document], List[Document]]:\n",
    "        chunks = self.text_splitter.split_documents(document)\n",
    "        print(f\"Total number of chunks in document: {len(chunks)}\")\n",
    "        contextualized_chunks = []\n",
    "        if self.create_contextual_rag:\n",
    "          contextualized_chunks = self._generate_contextualized_chunks(document, chunks, max_retries, delay)\n",
    "        return chunks, contextualized_chunks\n",
    "\n",
    "    def create_inmemory_vectorstores(self, chunks: List[Document]) -> FAISS:\n",
    "        return FAISS.from_documents(chunks, self.embeddings)\n",
    "\n",
    "    def create_vectorstores(self, chunks: List[Document]) -> FAISS:\n",
    "        return self.storage_class.add_documents(chunks)\n",
    "\n",
    "    def get_vectorstores(self):\n",
    "        return self.storage_class.get_index()\n",
    "\n",
    "    def save_vectorstores(self):\n",
    "        self.storage_class.save_index()\n",
    "\n",
    "    def get_bm25_index(self):\n",
    "        return self.bm25_index_manager\n",
    "\n",
    "    def create_bm25_index(self, chunks: List[Document]) -> BM25Okapi:\n",
    "        tokenized_chunks = [chunk.page_content.split() for chunk in chunks]\n",
    "        return BM25Okapi(tokenized_chunks)\n",
    "    \n",
    "    def create_flashrank_index(self,vectorstore):\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\":20})\n",
    "        compression_retriever = ContextualCompressionRetriever(base_compressor=FlashrankRerank(), base_retriever=retriever)\n",
    "        return compression_retriever\n",
    "\n",
    "    def create_bm25_retriever(self, chunks: List[Document]) -> BM25Retriever:\n",
    "        bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "        return bm25_retriever\n",
    "    \n",
    "    def create_ensemble_retriever_reranker(self, vectorstore, bm25_retriever) -> EnsembleRetriever:\n",
    "        retriever_vs = vectorstore.as_retriever(search_kwargs={\"k\":20})\n",
    "        bm25_retriever.k =10\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[retriever_vs, bm25_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "        redundant_filter = EmbeddingsRedundantFilter(embeddings=self.embeddings)\n",
    "        reranker = FlashrankRerank()\n",
    "        pipeline_compressor = DocumentCompressorPipeline(transformers=[redundant_filter, reranker])\n",
    "        compression_pipeline = ContextualCompressionRetriever(base_compressor=pipeline_compressor,\n",
    "                                                      base_retriever=ensemble_retriever)\n",
    "        return compression_pipeline\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_cache_key(document: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a cache key for a document.\n",
    "        \"\"\"\n",
    "        return hashlib.md5(document.encode()).hexdigest()\n",
    "\n",
    "    def generate_answer(self, query: str, relevant_chunks: List[str]) -> str:\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Based on the following information, please provide a concise and accurate answer to the question.\n",
    "        If the information is not sufficient to answer the question, say so.\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Relevant information:\n",
    "        {chunks}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        messages = prompt.format_messages(query=query, chunks=\"\\n\\n\".join(relevant_chunks))\n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "    def generate_answer_with_router(self, query: str, relevant_chunks: List[str]) -> str:\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Based on the following information, please provide a concise and accurate answer to the question.\n",
    "        If the information is not sufficient to answer the question, say so.\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Relevant information:\n",
    "        {chunks}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        messages = prompt.format_messages(query=query, chunks=\"\\n\\n\".join(relevant_chunks))\n",
    "\n",
    "        # Convert LangChain messages to OpenAI-compatible format\n",
    "        openai_messages = [\n",
    "            {\"role\": \"user\", \"content\": message.content}\n",
    "            for message in messages\n",
    "        ]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"router-mf-0.11593\",\n",
    "            messages=openai_messages\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleRetrieverReranker:\n",
    "    def __init__(self, embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: Embeddings model (e.g., OpenAIEmbeddings, SentenceTransformerEmbeddings).\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def _convert_numpy_to_float(self, obj):\n",
    "        \"\"\"\n",
    "        Recursively converts numpy.float32 values in a dictionary, list, or other object to native Python float.\n",
    "\n",
    "        Args:\n",
    "            obj: A dictionary, list, or other object.\n",
    "\n",
    "        Returns:\n",
    "            The same object with numpy.float32 values converted to float.\n",
    "        \"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: self._convert_numpy_to_float(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self._convert_numpy_to_float(item) for item in obj]\n",
    "        elif isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            # Convert numpy arrays to lists of floats\n",
    "            return obj.astype(float).tolist()\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def _process_document(self, doc):\n",
    "        \"\"\"\n",
    "        Processes a Document object to ensure all numpy.float32 values are converted to float.\n",
    "\n",
    "        Args:\n",
    "            doc: A Document object.\n",
    "\n",
    "        Returns:\n",
    "            Document: A processed Document object.\n",
    "        \"\"\"\n",
    "        # Convert metadata\n",
    "        if hasattr(doc, \"metadata\") and doc.metadata:\n",
    "            doc.metadata = self._convert_numpy_to_float(doc.metadata)\n",
    "\n",
    "        # Convert embeddings (if present)\n",
    "        if hasattr(doc, \"embedding\") and isinstance(doc.embedding, (np.ndarray, np.float32)):\n",
    "            doc.embedding = self._convert_numpy_to_float(doc.embedding)\n",
    "\n",
    "        return doc\n",
    "\n",
    "    def create_ensemble_retriever_reranker(self, vectorstore, bm25_retriever):\n",
    "        \"\"\"\n",
    "        Creates an ensemble retriever with a reranker.\n",
    "\n",
    "        Args:\n",
    "            vectorstore: Initialized FAISS vectorstore.\n",
    "            bm25_retriever: BM25 retriever to combine with the FAISS retriever.\n",
    "\n",
    "        Returns:\n",
    "            ContextualCompressionRetriever: An ensemble retriever with a reranker.\n",
    "        \"\"\"\n",
    "        if vectorstore is None:\n",
    "            raise ValueError(\n",
    "                \"FAISS vectorstore is not initialized. Ensure the vectorstore is loaded or created.\")\n",
    "\n",
    "        # Ensure the vectorstore is initialized\n",
    "        retriever_vs = vectorstore.as_retriever(search_kwargs={\"k\": 20})\n",
    "        bm25_retriever.k = 10\n",
    "\n",
    "        # Create ensemble retriever\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[retriever_vs, bm25_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "\n",
    "        # Add reranker and compression pipeline\n",
    "        redundant_filter = EmbeddingsRedundantFilter(\n",
    "            embeddings=self.embeddings)\n",
    "        reranker = FlashrankRerank()\n",
    "        pipeline_compressor = DocumentCompressorPipeline(\n",
    "            transformers=[redundant_filter, reranker])\n",
    "        compression_pipeline = ContextualCompressionRetriever(\n",
    "            base_compressor=pipeline_compressor,\n",
    "            base_retriever=ensemble_retriever\n",
    "        )\n",
    "\n",
    "        return compression_pipeline\n",
    "\n",
    "    def invoke(self, query, compression_pipeline):\n",
    "        \"\"\"\n",
    "        Invokes the ensemble retriever with reranker and preprocesses the results.\n",
    "\n",
    "        Args:\n",
    "            query: The query string.\n",
    "            compression_pipeline: The ensemble retriever with reranker.\n",
    "\n",
    "        Returns:\n",
    "            list[Document]: List of Document objects with all numpy.float32 values converted to float.\n",
    "        \"\"\"\n",
    "        # Use the `invoke` method to retrieve documents\n",
    "        docs = compression_pipeline.invoke(query)\n",
    "\n",
    "        # Process each document to ensure all numpy.float32 values are converted to float\n",
    "        processed_docs = [self._process_document(doc) for doc in docs]\n",
    "\n",
    "        return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "instruction = \"\"\"The provided document is a PDF file containing structured and unstructured content.\n",
    "It may include financial information, tables, management discussions, and analyses.\n",
    "Try to capture the essence of the document, including text, tables, and key highlights.\n",
    "Be precise and ensure data integrity while processing.\"\"\"\n",
    "\n",
    "async def parse_pdf(file_path: str):\n",
    "  parser = LlamaParse(\n",
    "      result_type=\"markdown\",\n",
    "      parsing_instruction=instruction,\n",
    "      max_timeout=5000,\n",
    "  )\n",
    "  return await parser.aload_data(file_path)\n",
    "\n",
    "async def load_and_combine_documents(folder_path: str, output_folder: str):\n",
    "  for filename in os.listdir(folder_path):\n",
    "    combined_content = \"\"\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if filename.endswith('.pdf'):\n",
    "        print(f\"Parsing {filename}...\")\n",
    "        parsed_data = await parse_pdf(file_path)\n",
    "        combined_content += f\"# Document: {filename}\\n\\n{parsed_data}\\n\\n\"\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {filename}\")\n",
    "    output_file = output_folder + \"/\" + os.path.splitext(filename)[0] + \".md\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(combined_content)\n",
    "    print(f\"All documents combined into {output_file}\")\n",
    "\n",
    "\n",
    "def read_markdown_with_loader(folder_path: str):\n",
    "  documents = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if filename.endswith('.md'):\n",
    "      loader = UnstructuredMarkdownLoader(file_path)\n",
    "      documents.append(loader.load())\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insatiate RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./dataset/source\"\n",
    "output_folder = \"./dataset/converted_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Unsupported file type: .DS_Store\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Unsupported file type: .DS_Store\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">.DS_Store.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95m.DS_Store.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing July-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2018</span>-People-&amp;amp;-Events_jand.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing July-\u001b[1;36m2018\u001b[0m-People-&amp;-Events_jand.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1d80c49c-4af2-4248-acac-f42d5144272e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1d80c49c-4af2-4248-acac-f42d5144272e/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">July-2018-People-</span>&amp;amp;-Events_jand.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mJuly-2018-People-\u001b[0m&amp;-Events_jand.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing Diabetes-Whitepaper.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing Diabetes-Whitepaper.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 98da3d6c-46d4-4c4b-ae9e-87030993d479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/98da3d6c-46d4-4c4b-ae9e-87030993d479/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Diabetes-Whitepaper.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mDiabetes-Whitepaper.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing The-Value-Proposition-of-Academy-Membership_2018_j.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing The-Value-Proposition-of-Academy-Membership_2018_j.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id a20e7c87-8872-4f27-99b2-ff8e46413092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/a20e7c87-8872-4f27-99b2-ff8e46413092 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/a20e7c87-8872-4f27-99b2-ff8e46413092 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/a20e7c87-8872-4f27-99b2-ff8e46413092 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/a20e7c87-8872-4f27-99b2-ff8e46413092 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/a20e7c87-8872-4f27-99b2-ff8e46413092/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">The-Value-Proposition-of-Academy-Membership_2018_j.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mThe-Value-Proposition-of-Academy-Membership_2018_j.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing AMA Perspective Paper <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Prevention in VBC <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102716.</span>pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing AMA Perspective Paper \u001b[1;36m1\u001b[0m Prevention in VBC \u001b[1;36m102716.\u001b[0mpdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 440a2a17-4b56-466d-867c-f3d992a9f757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/440a2a17-4b56-466d-867c-f3d992a9f757/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">AMA</span> Perspective Paper <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Prevention in VBC <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102716.</span>md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mAMA\u001b[0m Perspective Paper \u001b[1;36m1\u001b[0m Prevention in VBC \u001b[1;36m102716.\u001b[0mmd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing Table-of-Contents_jand.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing Table-of-Contents_jand.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cc0215b7-415f-4da1-9d52-88f21aff575f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cc0215b7-415f-4da1-9d52-88f21aff575f/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Table-of-Contents_jand.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mTable-of-Contents_jand.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing colbertv2.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing colbertv2.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f95dd458-8a82-4d2a-a996-c1903b3054fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/f95dd458-8a82-4d2a-a996-c1903b3054fd/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">colbertv2.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mcolbertv2.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing clip.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing clip.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 364bb1c3-aa4b-4ed3-8050-df6af5f3bacb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/364bb1c3-aa4b-4ed3-8050-df6af5f3bacb/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">clip.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mclip.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing colbert.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing colbert.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 8be739c4-ae0c-4c27-9c00-374fa06a77c7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/8be739c4-ae0c-4c27-9c00-374fa06a77c7/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">colbert.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mcolbert.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing ColPali_2407.01449v3.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing ColPali_2407.01449v3.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id bd4ad002-5f9e-4743-9c18-8453016f8bf0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bd4ad002-5f9e-4743-9c18-8453016f8bf0/result/markdown \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing the file './dataset/source/ColPali_2407.01449v3.pdf': 'markdown'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">ColPali_2407.01449v3.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mColPali_2407.01449v3.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing What-Is-a-National-Provider-Identifier-and-Why-Doe.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing What-Is-a-National-Provider-Identifier-and-Why-Doe.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4457da6e-6e1e-4bed-93f6-90c5bde1a1d3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4457da6e-6e1e-4bed-93f6-90c5bde1a1d3/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">What-Is-a-National-Provider-Identifier-and-Why-Doe.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mWhat-Is-a-National-Provider-Identifier-and-Why-Doe.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing Erratum_jand.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing Erratum_jand.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 586c9bf5-dadb-48a5-941f-3e6fdf872d22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/586c9bf5-dadb-48a5-941f-3e6fdf872d22/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Erratum_jand.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mErratum_jand.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing Inuit-Country-Food-Diet-Pattern-Is-Associated-with.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing Inuit-Country-Food-Diet-Pattern-Is-Associated-with.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 855b9b3a-3354-4c63-9030-624cb01e8aa0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/855b9b3a-3354-4c63-9030-624cb01e8aa0/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Inuit-Country-Food-Diet-Pattern-Is-Associated-with.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mInuit-Country-Food-Diet-Pattern-Is-Associated-with.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing What's-New-Online_jand.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing What's-New-Online_jand.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id af5fea8b-f0b7-4694-9b7f-aa48283146ef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/af5fea8b-f0b7-4694-9b7f-aa48283146ef \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/af5fea8b-f0b7-4694-9b7f-aa48283146ef \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/af5fea8b-f0b7-4694-9b7f-aa48283146ef \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/af5fea8b-f0b7-4694-9b7f-aa48283146ef \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/af5fea8b-f0b7-4694-9b7f-aa48283146ef \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/af5fea8b-f0b7-4694-9b7f-aa48283146ef/result/markdown \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing the file './dataset/source/What's-New-Online_jand.pdf': 'markdown'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">What</span>'s-New-Online_jand.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mWhat\u001b[0m's-New-Online_jand.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing vit.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing vit.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 143dc7d2-53c4-4f96-a966-de97c7a8ee5f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/143dc7d2-53c4-4f96-a966-de97c7a8ee5f/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">vit.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mvit.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Parsing July-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2018</span>-Classified-Advertisements_jand.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Parsing July-\u001b[1;36m2018\u001b[0m-Classified-Advertisements_jand.pdf\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 7555fe58-cc93-4b64-8608-26079a1d0b4f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7555fe58-cc93-4b64-8608-26079a1d0b4f/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All documents combined into .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">July-2018-Classified-Advertisements_jand.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All documents combined into .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mJuly-2018-Classified-Advertisements_jand.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await load_and_combine_documents(folder_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "documents = read_markdown_with_loader(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created directory: .<span style=\"color: #800080; text-decoration-color: #800080\">/storage/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">bm25_index</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created directory: .\u001b[35m/storage/\u001b[0m\u001b[95mbm25_index\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_contextual_rag = False\n",
    "my_rag = MyRAGPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Erratum_jand.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mErratum_jand.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating new FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating new FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saving FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saving FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m10\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m10\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">colbertv2.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mcolbertv2.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m83\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m83\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m83\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Table-of-Contents_jand.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mTable-of-Contents_jand.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m12\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m12\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m12\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">vit.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mvit.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m87\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m87\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m87\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">.DS_Store.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95m.DS_Store.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m0\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Failed to process document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">.DS_Store.md.</span> Error: not enough values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, \n",
       "got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Failed to process document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95m.DS_Store.md.\u001b[0m Error: not enough values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m2\u001b[0m, \n",
       "got \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Diabetes-Whitepaper.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mDiabetes-Whitepaper.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m5\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m5\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">July-2018-People-</span>&amp;amp;-Events_jand.md with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mJuly-2018-People-\u001b[0m&amp;-Events_jand.md with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m6\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m6\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Inuit-Country-Food-Diet-Pattern-Is-Associated-with.md</span> with currrent \n",
       "tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mInuit-Country-Food-Diet-Pattern-Is-Associated-with.md\u001b[0m with currrent \n",
       "tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m56\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m56\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m56\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">July-2018-Classified-Advertisements_jand.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mJuly-2018-Classified-Advertisements_jand.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m5\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m5\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">What-Is-a-National-Provider-Identifier-and-Why-Doe.md</span> with currrent \n",
       "tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mWhat-Is-a-National-Provider-Identifier-and-Why-Doe.md\u001b[0m with currrent \n",
       "tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m6\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m6\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">clip.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mclip.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m193\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m193\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m193\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">colbert.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mcolbert.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m41\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m41\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m41\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">The-Value-Proposition-of-Academy-Membership_2018_j.md</span> with currrent \n",
       "tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mThe-Value-Proposition-of-Academy-Membership_2018_j.md\u001b[0m with currrent \n",
       "tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m5\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m5\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">AMA</span> Perspective Paper <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Prevention in VBC <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102716.</span>md with currrent \n",
       "tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mAMA\u001b[0m Perspective Paper \u001b[1;36m1\u001b[0m Prevention in VBC \u001b[1;36m102716.\u001b[0mmd with currrent \n",
       "tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m19\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m19\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m19\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">What</span>'s-New-Online_jand.md with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mWhat\u001b[0m's-New-Online_jand.md with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m1\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m1\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing document: .<span style=\"color: #800080; text-decoration-color: #800080\">/dataset/converted_md/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">ColPali_2407.01449v3.md</span> with currrent tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing document: .\u001b[35m/dataset/converted_md/\u001b[0m\u001b[95mColPali_2407.01449v3.md\u001b[0m with currrent tokens: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of chunks in document: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of chunks in document: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Adding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> documents to the FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Adding \u001b[1;36m1\u001b[0m documents to the FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> documents to the index.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Added \u001b[1;36m1\u001b[0m documents to the index.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saving FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saving FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retry_document_processing = []\n",
    "current_tokens = 0\n",
    "\n",
    "for document in documents:\n",
    "  current_tokens = my_rag.process_document(document, retry_document_processing, current_tokens, 22)\n",
    "\n",
    "# Retry processing failed documents\n",
    "if retry_document_processing:\n",
    "    print(\"Retrying failed documents...\")\n",
    "    for document in retry_document_processing:\n",
    "        current_tokens = my_rag.process_document(document, retry_document_processing, current_tokens, 120)\n",
    "\n",
    "my_rag.save_vectorstores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create retriver system with hybrid search with Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading existing FAISS index<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading existing FAISS index\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'relevance_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98651373</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'./dataset/converted_md/clip.md'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">metadata_separator='\\\\n', text_resource=MediaResource(embeddings=None, data=None, text='The document discusses the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance of CLIP (Contrastive Language-Image Pretraining) models in comparison to various state-of-the-art </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computer vision models across multiple datasets. Here are the key highlights:\\\\n\\\\n1. Performance Metrics:\\\\n- The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">average scores of CLIP models are evaluated against other models like EfficientNet, MoCo, and ResNet across two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sets of datasets: 12 datasets from Kornblith et al. and a broader set of 27 datasets.\\\\n- The results indicate that</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">CLIP models outperform all evaluated systems in terms of compute efficiency, with improvements in average scores </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ranging from 2.6% to 5%.\\\\n\\\\n2. Dataset\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'relevance_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97326386</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'./dataset/converted_md/clip.md'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Performance Validation: CLIP is pre-trained for image-text retrieval on a noisy web-scale </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset. The zero-shot transfer performance of CLIP is validated on the Flickr30k and MSCOCO datasets.\\\\n- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Results:\\\\n- CLIP matches or outperforms previous zero-shot results on Flickr30k and MSCOCO.\\\\n- On Flickr30k, CLIP</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is competitive with the state-of-the-art (SOTA) for text retrieval but lags behind in image retrieval.\\\\n- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fine-tuning on MSCOCO significantly improves performance, but zero-shot CLIP does not compete with the latest </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models.\\\\n- Adding the prompt \"a photo of\" to image descriptions boosts performance by 1-2 points.\\\\n\\\\n#### E.2. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Optical Character Recognition\\\\n- Initial Observations: CLIP began to develop primitive OCR capabilities during its</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training, which improved over time.\\\\n-'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'relevance_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9483653</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'./dataset/converted_md/clip.md'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The analysis indicates that CLIP struggles with fine-grained classification tasks and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systematic tasks, such as counting objects in images.\\\\n\\\\n3. Generalization Challenges:\\\\n- CLIP's zero-shot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance is limited when faced with novel tasks or data that is out-of-distribution, leading to near-random </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance in some cases.\\\\n- The document suggests that while CLIP can generate zero-shot classifiers, it is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">restricted to concepts present in its pre-training dataset, which limits its flexibility compared to generative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models like image captioning.\\\\n\\\\n4. Future Directions:\\\\n- The need for further research into improving CLIP's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computational and data efficiency is emphasized, as a significant increase in compute resources (estimated at </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">1000x) would be required for CLIP to reach\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'relevance_score'\u001b[0m: \u001b[1;36m0.98651373\u001b[0m, \u001b[32m'source'\u001b[0m: \u001b[32m'./dataset/converted_md/clip.md'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"excluded_llm_metadata_keys\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mrelationships\u001b[0m\u001b[32m=\u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmetadata_template\u001b[0m\u001b[32m='\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkey\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m}\u001b[0m\u001b[32m', \u001b[0m\n",
       "\u001b[32mmetadata_separator\u001b[0m\u001b[32m='\\\\n', \u001b[0m\u001b[32mtext_resource\u001b[0m\u001b[32m=\u001b[0m\u001b[32mMediaResource\u001b[0m\u001b[32m(\u001b[0m\u001b[32membeddings\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdata\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mtext\u001b[0m\u001b[32m='The document discusses the \u001b[0m\n",
       "\u001b[32mperformance of CLIP \u001b[0m\u001b[32m(\u001b[0m\u001b[32mContrastive Language-Image Pretraining\u001b[0m\u001b[32m)\u001b[0m\u001b[32m models in comparison to various state-of-the-art \u001b[0m\n",
       "\u001b[32mcomputer vision models across multiple datasets. Here are the key highlights:\\\\n\\\\n1. Performance Metrics:\\\\n- The \u001b[0m\n",
       "\u001b[32maverage scores of CLIP models are evaluated against other models like EfficientNet, MoCo, and ResNet across two \u001b[0m\n",
       "\u001b[32msets of datasets: 12 datasets from Kornblith et al. and a broader set of 27 datasets.\\\\n- The results indicate that\u001b[0m\n",
       "\u001b[32mCLIP models outperform all evaluated systems in terms of compute efficiency, with improvements in average scores \u001b[0m\n",
       "\u001b[32mranging from 2.6% to 5%.\\\\n\\\\n2. Dataset\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'relevance_score'\u001b[0m: \u001b[1;36m0.97326386\u001b[0m, \u001b[32m'source'\u001b[0m: \u001b[32m'./dataset/converted_md/clip.md'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Performance Validation: CLIP is pre-trained for image-text retrieval on a noisy web-scale \u001b[0m\n",
       "\u001b[32mdataset. The zero-shot transfer performance of CLIP is validated on the Flickr30k and MSCOCO datasets.\\\\n- \u001b[0m\n",
       "\u001b[32mResults:\\\\n- CLIP matches or outperforms previous zero-shot results on Flickr30k and MSCOCO.\\\\n- On Flickr30k, CLIP\u001b[0m\n",
       "\u001b[32mis competitive with the state-of-the-art \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSOTA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for text retrieval but lags behind in image retrieval.\\\\n- \u001b[0m\n",
       "\u001b[32mFine-tuning on MSCOCO significantly improves performance, but zero-shot CLIP does not compete with the latest \u001b[0m\n",
       "\u001b[32mmodels.\\\\n- Adding the prompt \"a photo of\" to image descriptions boosts performance by 1-2 points.\\\\n\\\\n#### E.2. \u001b[0m\n",
       "\u001b[32mOptical Character Recognition\\\\n- Initial Observations: CLIP began to develop primitive OCR capabilities during its\u001b[0m\n",
       "\u001b[32mtraining, which improved over time.\\\\n-'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'relevance_score'\u001b[0m: \u001b[1;36m0.9483653\u001b[0m, \u001b[32m'source'\u001b[0m: \u001b[32m'./dataset/converted_md/clip.md'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m analysis indicates that CLIP struggles with fine-grained classification tasks and \u001b[0m\n",
       "\u001b[32msystematic tasks, such as counting objects in images.\\\\n\\\\n3. Generalization Challenges:\\\\n- CLIP's zero-shot \u001b[0m\n",
       "\u001b[32mperformance is limited when faced with novel tasks or data that is out-of-distribution, leading to near-random \u001b[0m\n",
       "\u001b[32mperformance in some cases.\\\\n- The document suggests that while CLIP can generate zero-shot classifiers, it is \u001b[0m\n",
       "\u001b[32mrestricted to concepts present in its pre-training dataset, which limits its flexibility compared to generative \u001b[0m\n",
       "\u001b[32mmodels like image captioning.\\\\n\\\\n4. Future Directions:\\\\n- The need for further research into improving CLIP's \u001b[0m\n",
       "\u001b[32mcomputational and data efficiency is emphasized, as a significant increase in compute resources \u001b[0m\u001b[32m(\u001b[0m\u001b[32mestimated at \u001b[0m\n",
       "\u001b[32m1000x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m would be required for CLIP to reach\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:22:34 - LiteLLM:INFO\u001b[0m: utils.py:2802 - \n",
      "LiteLLM completion() model= mixtral-8x7b-32768; provider = groq\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= mixtral-8x7b-32768; provider = groq\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:22:34 - LiteLLM:INFO\u001b[0m: utils.py:949 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The full form of CLIP in the given context is Contrastive Language-Image Pretraining. It is a model that is \n",
       "pre-trained for image-text retrieval on a noisy web-scale dataset and has been found to outperform other models in \n",
       "terms of compute efficiency. However, it faces challenges in generalization, particularly with novel tasks or data \n",
       "outside its pre-training dataset. Further research is necessary to improve its computational and data efficiency.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The full form of CLIP in the given context is Contrastive Language-Image Pretraining. It is a model that is \n",
       "pre-trained for image-text retrieval on a noisy web-scale dataset and has been found to outperform other models in \n",
       "terms of compute efficiency. However, it faces challenges in generalization, particularly with novel tasks or data \n",
       "outside its pre-training dataset. Further research is necessary to improve its computational and data efficiency.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_manager = my_rag.get_bm25_index()\n",
    "vectorstore = my_rag.get_vectorstores()\n",
    "\n",
    "bm25_retriever = WhooshRetriever(index_manager=index_manager, k=10)\n",
    "ensemble_retriever_reranker = my_rag.create_ensemble_retriever_reranker(vectorstore, bm25_retriever)\n",
    "\n",
    "query = \"What is the fullform of CLIP\"\n",
    "ensemble_retriever_reranker_results = ensemble_retriever_reranker.invoke(query)\n",
    "print(ensemble_retriever_reranker_results)\n",
    "\n",
    "ensemble_retriever_reranker_answer = my_rag.generate_answer_with_router(query, [doc.page_content for doc in ensemble_retriever_reranker_results])\n",
    "print(ensemble_retriever_reranker_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
